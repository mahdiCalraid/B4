# GCP Configuration
GCP_PROJECT_ID=your-project-id
GCP_REGION=us-central1

# Storage Buckets
GCS_BUCKET_RAW=world-raw
GCS_BUCKET_PROCESSED=world-processed

# Firestore
FIRESTORE_DATABASE=(default)

# BigQuery
BQ_DATASET=world_model
BQ_LOCATION=US

# Pub/Sub Topics
PUBSUB_TOPIC_INGEST=world-ingest
PUBSUB_TOPIC_PROCESS=world-process

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# LLM Configuration (for claim extraction fallback)
LLM_PROVIDER=openai  # or vertex-ai, anthropic
LLM_MODEL=gpt-3.5-turbo
LLM_MAX_TOKENS=500
LLM_CONFIDENCE_THRESHOLD=0.6

# Processing Configuration
BATCH_SIZE=100
DEDUP_WINDOW_HOURS=24
MAX_RETRIES=3

# Feature Flags
ENABLE_LLM_FALLBACK=true
ENABLE_BIGQUERY_ANALYTICS=false
DEBUG_MODE=false